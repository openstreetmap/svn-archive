
Trapi has only been tested on Debian unstable on x86 machines, but
should work on any modern unix-derived OS.  For Debian, you will need
the packages listed in packages.  (or equivelents if you prefer
another web server than apache2.)  The data files are
endian-independent.  Porting to Microsoft would be a challenge, there
are subtle dependencies on a reasonable OS.

The code depends on pack supporting "N!" for signed 32-bit values.
This feature is apparently new at perl 5.10.

The time on the system should be close to correct.  If it is off by
more than a minute it could affect the data update process.  The map
fcgi-bin program will refuse to serve data if the clock is too far in
the future.

Trapi does many seeks and small reads and writes, on millions of small
files.  The indexes are fairly large (Around 2.5 Gb in 4 files as of
December 2008.)  The data files should be on a filesystem set up for
many small files.  If using ext2 or ext3, directory indexing should be
on and using a 1 or 2kbyte allocation will save disk space.  (mke2fs
-j -O dir_index -b 1024 -i 2048 works well.)  (About 13 Gb and 7.5
million inodes as of December 2008.)  Room for both growth and garbage
to accumulate should be planned for.  Low latency disks and lots of
memory to cache the files are recomended.

The only part of trapi that tends to be CPU bound is the database
import and update.  This is single-threaded other than the file
decompression, so not much benifit is had with more than 2 cores.

The configuration of trapi is in trapi.pm.  Constants that probably
shouldn't be changed are defined in ptdb.pm.  VERBOSE is for how many
messages to output.  1 will be only detected problems in the data, 25
will be many debugging messages.  TRAPIDIR is where the trapi data
files are stored.  DBDIR is for the indexes that are larger files.
MAXOPEN is the number of data files to open at once, not including the
indexes.  Bigger is generally better if your OS can handle it.
KEEPOPEN should be a bit less, closer to MAXOPEN will mean more CPU
and less file opening.  SPLIT is the number of bytes in a node data
file before splitting to higher zoom.  (16 bytes/node) IGNORETAGS is a
regular expression to match tags that will not be stored in the
database.  (Use '' to store all tags.)  GCCOUNT is the number of tiles
to garbage collect per change file processed.  (Setting it low will
cause the list of tiles to be garbage-collected to build up in busy
times.)  OSCDELAY, WAITDELAY, and WAITFAIL determine how the change
files are checked for.

The .pm files need to be where your perl will find them, and the
executable files where your shell will find them.

Trapi does not need special priveliges.  Your web server will need
read access to the trapi database and indexes.

Initial data load:

   cleardb
   bzcat planet.bz2 | tahdbload.pl
   echo YYYYMMDD >timestamp

YYYYMMDD is the day before the planet file was generated.  It's better
to reprocess a bit of duplicated data than miss something.  The
initial data load is disk IO intensive and will take several days.


Updating the data:

   trup.pl | trpcs.pl

This will fetch the daily, hourly, and minute diff files and update
the trapi database.  It will complete processing the currently fetched
data then stop if the file stopfile.txt exists.  timestamp will be
updated as the diff files are processed.


Garbage collection:

   trgarb.pl

Garbage collection must be done when nothing else is updating the
database.  It takes a little over a day.  How often this should be
done is to be determined.  stopfile.txt will stop the garbage
collection.


Web access:

map is a fastcgi script.  Your web server should be configured so
api/0.5/map requests will go to it.




Trapi will return more data than requested.  All request are rounded
up to z14 tile boundaries, and in low node density areas may be up to
z11.  Some tags not used by tiles@home are not stored by trapi.  The
user and timestamp information is also not stored.  This is fine for
tiles@home, but trapi data must not be uploaded to openstreetmap.
Ways and relations that are no longer in the requested area may be
returned.



UPDATE NOTE:

When updating from a version prior to Jan 9, 2009 you'll need to put
your configuraiton in trapi.pm and the relation files need to be
rebuilt.  (or a complete database rebuild) Since relation extracts of
planet files are available, this can be done: (This takes most of a
day.)

   cd TRAPIDIR
   touch stopfile.txt
   wait for trpcs.pl to stop
   find z0 z1? -name relation -print | xargs rm
   bzcat relation-DATE.osm.bz2 | tahdbload.pl
   echo YYYYMMDD > timestamp
   restart trpcs
